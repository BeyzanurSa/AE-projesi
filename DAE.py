# -*- coding: utf-8 -*-
"""DAE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tn9DYV53gmAEq9SDVk-1d3a3-kakR08M
"""

import tensorflow as tf
tf.config.list_physical_devices('GPU')

# Commented out IPython magic to ensure Python compatibility.
# Colab i√ßin ayarlar
# %matplotlib inline

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist, fashion_mnist
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.ensemble import RandomForestClassifier
from skimage.metrics import structural_similarity as ssim
import seaborn as sns
import warnings
import tensorflow as tf
warnings.filterwarnings('ignore')

class DenoisingAutoencoderProject:
    def __init__(self):
        self.models = {}
        self.histories = {}
        self.noise_factors = [0.1, 0.3, 0.5, 0.7]

    def load_and_preprocess_data(self, dataset='mnist'):
        if dataset == 'mnist':
            (x_train, y_train), (x_test, y_test) = mnist.load_data()
        else:
            (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
        x_train = x_train.astype("float32") / 255.0
        x_test = x_test.astype("float32") / 255.0
        x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))
        x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))
        return (x_train, y_train), (x_test, y_test)

    def add_noise(self, data, noise_factor):
        noisy_data = data + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data.shape)
        return np.clip(noisy_data, 0., 1.)

    def create_simple_autoencoder(self, input_shape=(28, 28, 1)):
        input_img = Input(shape=input_shape)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
        x = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        encoded = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        x = UpSampling2D((2, 2))(x)
        decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
        autoencoder = Model(input_img, decoded)
        encoder = Model(input_img, encoded)
        autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mse'])
        return autoencoder, encoder

    def create_deep_autoencoder(self, input_shape=(28, 28, 1)):
        input_img = Input(shape=input_shape)
        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)
        x = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        x = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)
        encoded = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
        x = UpSampling2D((2, 2))(x)
        decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
        autoencoder = Model(input_img, decoded)
        encoder = Model(input_img, encoded)
        autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mse'])
        return autoencoder, encoder

    def calculate_psnr(self, original, denoised):
        mse = np.mean((original - denoised) ** 2)
        if mse == 0:
            return float('inf')
        psnr = 20 * np.log10(1.0 / np.sqrt(mse))
        return psnr

    def calculate_ssim(self, original, denoised):
        return np.mean([ssim(original[i].squeeze(), denoised[i].squeeze(), data_range=1.0)
                        for i in range(original.shape[0])])

    def train_model(self, model, x_train_noisy, x_train_clean, x_test_noisy, x_test_clean, model_name, epochs=10):
        callbacks = [
            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)
        ]
        history = model.fit(x_train_noisy, x_train_clean,
                            validation_data=(x_test_noisy, x_test_clean),
                            epochs=epochs, batch_size=128,
                            callbacks=callbacks, verbose=2)
        return history

    def plot_results(self, x_test_clean, x_test_noisy, decoded_imgs, n=10):
        plt.figure(figsize=(20, 6))
        for i in range(n):
            # Original
            ax = plt.subplot(3, n, i + 1)
            plt.imshow(x_test_clean[i].reshape(28, 28), cmap='gray')
            plt.title("Original")
            plt.axis("off")

            # Noisy
            ax = plt.subplot(3, n, i + 1 + n)
            plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')
            plt.title("Noisy")
            plt.axis("off")

            # Denoised
            ax = plt.subplot(3, n, i + 1 + 2 * n)
            plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')
            plt.title("Denoised")
            plt.axis("off")
        plt.show()

    def add_gaussian_noise(self, data, noise_factor):
        """Gaussian (Normal) g√ºr√ºlt√º ekler"""
        noisy_data = data + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data.shape)
        return np.clip(noisy_data, 0., 1.).astype('float32')

    def add_salt_pepper_noise(self, data, noise_factor):
        """Salt and Pepper g√ºr√ºlt√ºs√º ekler"""
        noisy_data = np.copy(data)
        # Salt (beyaz noktalar)
        salt_mask = np.random.random(data.shape) < noise_factor/2
        noisy_data[salt_mask] = 1.0
        # Pepper (siyah noktalar)
        pepper_mask = np.random.random(data.shape) < noise_factor/2
        noisy_data[pepper_mask] = 0.0
        return noisy_data.astype('float32')

    def add_speckle_noise(self, data, noise_factor):
        """Speckle g√ºr√ºlt√ºs√º ekler (√ßarpƒ±msal g√ºr√ºlt√º)"""
        noise = np.random.normal(loc=0, scale=noise_factor, size=data.shape)
        noisy_data = data + data * noise
        return np.clip(noisy_data, 0., 1.).astype('float32')

    def add_poisson_noise(self, data, noise_factor=None):
        """Poisson g√ºr√ºlt√ºs√º ekler"""
        # Poisson g√ºr√ºlt√ºs√º i√ßin veriyi √∂l√ßeklendirme
        scaled_data = data * 255
        noisy_data = np.random.poisson(scaled_data) / 255.0
        return np.clip(noisy_data, 0., 1.).astype('float32')

    def add_uniform_noise(self, data, noise_factor):
        """Uniform g√ºr√ºlt√º ekler"""
        noise = np.random.uniform(-noise_factor, noise_factor, data.shape)
        noisy_data = data + noise
        return np.clip(noisy_data, 0., 1.).astype('float32')

    def create_all_noise_types(self, data, noise_factor=0.3):
        """T√ºm g√ºr√ºlt√º t√ºrlerini olu≈üturur"""
        noise_types = {
            'gaussian': self.add_gaussian_noise(data, noise_factor),
            'salt_pepper': self.add_salt_pepper_noise(data, noise_factor),
            'speckle': self.add_speckle_noise(data, noise_factor),
            'poisson': self.add_poisson_noise(data),
            'uniform': self.add_uniform_noise(data, noise_factor)
        }
        return noise_types

    def plot_noise_comparison(self, original_img, noise_types, img_index=0):
        """Farklƒ± g√ºr√ºlt√º t√ºrlerini kar≈üƒ±la≈ütƒ±rmalƒ± g√∂sterir"""
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))

        # Orijinal g√∂r√ºnt√º
        axes[0, 0].imshow(original_img[img_index].reshape(28, 28), cmap='gray')
        axes[0, 0].set_title('Original', fontsize=12)
        axes[0, 0].axis('off')

        # G√ºr√ºlt√ºl√º g√∂r√ºnt√ºler
        positions = [(0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]
        noise_names = ['Gaussian', 'Salt & Pepper', 'Speckle', 'Poisson', 'Uniform']

        for i, (noise_type, noisy_data) in enumerate(noise_types.items()):
            row, col = positions[i]
            axes[row, col].imshow(noisy_data[img_index].reshape(28, 28), cmap='gray')
            axes[row, col].set_title(f'{noise_names[i]} Noise', fontsize=12)
            axes[row, col].axis('off')

        plt.tight_layout()
        plt.show()

    # Kullanƒ±m √∂rneƒüi (mevcut kodunuzun sonuna ekleyin):
    def run_noise_comparison_experiment(self):
        """Farklƒ± g√ºr√ºlt√º t√ºrleri ile deneme yapar"""
        # Veri y√ºkle
        (x_train, y_train), (x_test, y_test) = self.load_and_preprocess_data('mnist')

        # Farklƒ± g√ºr√ºlt√º t√ºrleri olu≈ütur
        noise_factor = 0.3
        # Slice x_test to 1000 samples for creating noise types
        noise_types = self.create_all_noise_types(x_test[:1000], noise_factor)

        # G√ºr√ºlt√º kar≈üƒ±la≈ütƒ±rmasƒ± g√∂ster
        self.plot_noise_comparison(x_test, noise_types, img_index=0)

        results = {}

        # Her g√ºr√ºlt√º t√ºr√º i√ßin model eƒüit ve test et
        for noise_name, noisy_test in noise_types.items():
            print(f"\nüîß {noise_name.upper()} g√ºr√ºlt√ºs√º ile eƒüitim ba≈ülƒ±yor...")

            # Eƒüitim verisi i√ßin aynƒ± g√ºr√ºlt√º t√ºr√ºn√º uygula
            if noise_name == 'gaussian':
                noisy_train = self.add_gaussian_noise(x_train, noise_factor)
            elif noise_name == 'salt_pepper':
                noisy_train = self.add_salt_pepper_noise(x_train, noise_factor)
            elif noise_name == 'speckle':
                noisy_train = self.add_speckle_noise(x_train, noise_factor)
            elif noise_name == 'poisson':
                noisy_train = self.add_poisson_noise(x_train)
            elif noise_name == 'uniform':
                noisy_train = self.add_uniform_noise(x_train, noise_factor)

            # Slice training data to match validation data size
            noisy_train = noisy_train[:1000]
            x_train_sliced = x_train[:1000]


            # Model olu≈ütur ve eƒüit
            autoencoder, encoder = self.create_simple_autoencoder()
            history = self.train_model(autoencoder, noisy_train, x_train_sliced,
                                     noisy_test, x_test[:1000],
                                     f"AE_{noise_name}", epochs=5)

            # Tahmin ve metrikler
            decoded_imgs = autoencoder.predict(noisy_test[:100], verbose=0)
            psnr = self.calculate_psnr(x_test[:100], decoded_imgs)
            ssim_score = self.calculate_ssim(x_test[:100], decoded_imgs)

            results[noise_name] = {
                'psnr': psnr,
                'ssim': ssim_score,
                'decoded': decoded_imgs
            }

            print(f"üìä {noise_name.upper()} - PSNR: {psnr:.2f} dB, SSIM: {ssim_score:.4f}")

        return results

# Proje ba≈ülat
project = DenoisingAutoencoderProject()

# Veri y√ºkleme
(x_train, y_train), (x_test, y_test) = project.load_and_preprocess_data('mnist')

# G√ºr√ºlt√º ekle
noise_factor = 0.5
x_train_noisy = project.add_noise(x_train, noise_factor)
x_test_noisy = project.add_noise(x_test, noise_factor)

# Model olu≈ütur ve eƒüit
autoencoder, encoder = project.create_simple_autoencoder()
history = project.train_model(autoencoder, x_train_noisy, x_train, x_test_noisy, x_test, "SimpleAE", epochs=10)

# Tahmin ve metrikler
decoded_imgs = autoencoder.predict(x_test_noisy, verbose=0)
psnr = project.calculate_psnr(x_test, decoded_imgs)
ssim_score = project.calculate_ssim(x_test, decoded_imgs)

print(f"üìä PSNR: {psnr:.2f} dB")
print(f"üìä SSIM: {ssim_score:.4f}")

# G√∂rselle≈ütirme
project.plot_results(x_test, x_test_noisy, decoded_imgs)

# G√ºr√ºlt√º kar≈üƒ±la≈ütƒ±rma deneyi √ßalƒ±≈ütƒ±r
results = project.run_noise_comparison_experiment()

# Sonu√ßlarƒ± kar≈üƒ±la≈ütƒ±rmalƒ± g√∂ster
def plot_performance_comparison(results):
    noise_types = list(results.keys())
    psnr_values = [results[nt]['psnr'] for nt in noise_types]
    ssim_values = [results[nt]['ssim'] for nt in noise_types]

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

    # PSNR kar≈üƒ±la≈ütƒ±rmasƒ±
    ax1.bar(noise_types, psnr_values, color=['skyblue', 'lightgreen', 'salmon', 'gold', 'plum'])
    ax1.set_title('PSNR Comparison by Noise Type')
    ax1.set_ylabel('PSNR (dB)')
    ax1.tick_params(axis='x', rotation=45)

    # SSIM kar≈üƒ±la≈ütƒ±rmasƒ±
    ax2.bar(noise_types, ssim_values, color=['skyblue', 'lightgreen', 'salmon', 'gold', 'plum'])
    ax2.set_title('SSIM Comparison by Noise Type')
    ax2.set_ylabel('SSIM Score')
    ax2.tick_params(axis='x', rotation=45)

    plt.tight_layout()
    plt.show()

plot_performance_comparison(results)